{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 宿題シート: クラス(class)\n",
    "\n",
    "このファイルの名前を以下のように変更して，締切までに提出しましょう。\n",
    "```\n",
    "6-class-<学籍番号>-<名前>.ipynb\n",
    "例) 6-class-16-2202-099-9-YamaguchiDai.ipynb\n",
    "```\n",
    "\n",
    "- 名前は必ず，姓名の順にすること\n",
    "- **ファイル名が不適切な場合は減点**します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 課題\n",
    "- 以下の説明文や例文を読みなさい。\n",
    "- 各説明文や例文のあとにあるCodeセルでは以下を実行しなさい。\n",
    "    - **設問(Q)がある場合**にはその解答を書き，実行しなさい。**セル内にヒントがないときにはテキストを参照**しなさい。\n",
    "    - **設問(Q)がない場合**には，例文等をCodeセルで実際に実行して動作を確認しなさい。**例文はそのままコピペせず，少し違う内容に**して試しなさい\n",
    "- なんらかの演算やしたり，命令文作ったときは，その**結果が予想通りか否かを必ず確認しなさい**\n",
    "\n",
    "## そのほか\n",
    "- **設問(Q)があるセルは書き換えない**でください。\n",
    "- 設問がない説明文のセルは，加筆してもいいですが，すでにある内容は消さないでください。\n",
    "- 必要に応じてセルを増やしても構いません。役立ちそうな情報を追記しておくと，今後プログラムを組む上で便利なメモになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# クラス(Class), p.273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## クラス, インスタンス，オブジェクト\n",
    "\n",
    "### クラス\n",
    "- pythonにおける型のようなもの。予め定義されているものもあるが，ユーザが定義して使うこともできる。\n",
    "- 例) int, float, list, tuple, dict\n",
    "\n",
    "### インスタンス(例)\n",
    "- クラス(型)から生成されるデータのこと。インスタンス・オブジェクトともいう\n",
    "- intはクラス，1,2,..はインスタンス\n",
    "- listはクラス, [1,3]はインスタンス\n",
    "\n",
    "### オブジェクト(もの)\n",
    "- 例) クラスもインスタンスもメソッドもオブジェクト。定義できるものはなんでもかんでも。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## クラスを作る, p.282\n",
    "\n",
    "\n",
    "### キーワード\n",
    "- **初期化メソッド**\n",
    "    - 定義したクラスをインスタンス化するときに実行される関数\n",
    "- **インスタンス変数**\n",
    "    - クラス定義中では`self.変数名`で生成・参照。\n",
    "    - インスタンス化したオブジェクトからは，`オブジェクト名.変数名` で参照\n",
    "- **インスタンス・メソッド**\n",
    "    - クラス定義中では第一引数に`self`を指定して定義する関数\n",
    "    - クラス定義中では`self.関数名` で参照できる(引数からは`self`は省略)\n",
    "    。インスタンス化したオブジェクトからは，`オブジェクト名.関数名` で参照(引数からは`self`は省略)\n",
    "\n",
    "### クラス定義の方法\n",
    "\n",
    "**Q.** 上記のクラス宣言の間違いを直しなさい。また，適当な名前(name)を引数とするインスタンスを作り，動作確認をしてみなさい。\n",
    "```python\n",
    "class Student:\n",
    "    def __init__(self, name=\"someone\"): # 初期化メソッド(インスタンス生成時に実行)\n",
    "        self.name=name  # インスタンス変数\n",
    "        self.physics=0  # インスタンス変数には\"self.\"をつける\n",
    "        self.math=0     # インスタンス変数は，以下で定義するインスタンスメソッドのいずれでも使える\n",
    "\n",
    "    def get_total(self):  # インスタンス・メソッド(第一引数は必ずself)\n",
    "        total=self.physics+self.math  # 変数totalはget_score()のみで使う局所変数なので，インスタンス変数にはしない\n",
    "        return(total)                 # (なんでもかんでもインスタンス変数にしてはいけない!)\n",
    "\n",
    "    def print_total(): # インスタンス・メソッド。この行に間違いがある。\n",
    "        print(name, self.get_total())  # この行にも間違いがある\n",
    "\n",
    "# クラスStudentの定義はここまで。以下はインスタンス・オブジェクトの生成    \n",
    "taro=Student(\"Taro Yamada\")  # インスタンスを生成し，変数taroに代入\n",
    "jiro=Student(\"Jiro Tanaka\")\n",
    "\n",
    "taro.physics=80 # インスタンス変数には，\"オブジェクト名.インスタンス変数名\"でアクセスできる(selfがオブジェクト名と置き換わる)\n",
    "taro.math=70\n",
    "\n",
    "jiro.physics=50\n",
    "jiro.math=90\n",
    "\n",
    "taro.print_total() # インスタンス・メソッドには，\"オブジェクト名.メソッド名\"でアクセスできる\n",
    "jiro.print_total()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## お部屋の探検と強化学習\n",
    "一列に並んだNstate個の部屋(s=1,2...,Nstate)がある。中にいるエージェントが行動として\"left\"か\"right\"を選ぶことができ，それぞれ部屋番号の小さい，もしくは大きいほうの隣の部屋に移動する。部屋1で\"left\"，もしくは部屋Nstateで\"right\"を選択すると，エピソードは終了となる。また，部屋Nstateで行動\"right\"を選択したときのみ，報酬(reward)として10を得ることができる。**それ以外の場合は報酬(reward)は-1**である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 学習環境の構築: class Rooms\n",
    "\n",
    "**Q1.** 上記説明にあった環境を表現するクラス`Rooms`を定義しなさい。\n",
    "    - 以下の仕様を満たしていれば，メソッドや変数の追加は自由にして良い\n",
    "    - 注) **各メソッド内のみで使う変数はインスタンス変数にはしない!**\n",
    "\n",
    "**仕様**\n",
    "- Class名: `Rooms`\n",
    "- 初期化メソッド`__init__(self,Nstate=5)`\n",
    "    - 引数は Nstate (部屋数)。そのデフォルト値は5\n",
    "    - インスタンス変数と初期化\n",
    "        - `state_list=[1,2,...,Nstate]`: 状態リスト(range()を使って定義)\n",
    "        - `r` :報酬値。初期値として-1を代入\n",
    "- インスタンス・メソッド\n",
    "    - `reset(self,s=None)`: エージェントの状態をリセットする\n",
    "        - 処理内容:\n",
    "            - 引数`s`が`None`の場合，インスタンス変数`s`(エージェントの状態)の値はリスト `state_list` の要素からランダムに選択して決定(`random.choice()`を使う)\n",
    "            - 引数`s`が`None`ではない場合，その値をインスタンス変数`s`(エージェントの状態)に代入\n",
    "            - インスタンス変数`r`の値を-1に初期化\n",
    "        - 返り値: インスタンス変数s\n",
    "    - `step(self,a)`: エージェントの行動に応じた状態遷移をし，報酬決定やエピソード終了判定を行う\n",
    "        - 処理内容:\n",
    "            - 引数`a`(エージェントの行動)に応じて，インスタンス変数`s`(状態)を変更\n",
    "            - 状態遷移による報酬値の決定と，エピソード終了判定\n",
    "        - 返り値:\n",
    "            - インスタンス変数`s`: 行動`a`による遷移後の新しい状態\n",
    "                - エピソード終了時の状態`s`は，0 (状態1の左)もしくは`Nstate+1` (`Nstate`の右)とする\n",
    "            - インスタンス変数`r`: 報酬値\n",
    "            - 変数`terminal`: エピソード終了フラグ。エピソード終了時に`True`, それ以外には`False`\n",
    "    - `render(self)`: エージェントがどこにいるかを，インスタンス変数`s`に応じて表示\n",
    "        - 処理内容:\n",
    "            - エージェントは@マークで表す。\n",
    "            - 右外に，得られた報酬値を表示\n",
    "            - 例) `s=2` の場合(`Nstate=5`とする)\n",
    "            ```\n",
    "            |1|@|3|4|5| r=0\n",
    "            ```\n",
    "            - 例) `s=Nstate+1`の場合(`Nstate=5`とする)\n",
    "            ```\n",
    "            |1|2|3|4|5|@ r=10\n",
    "            ```\n",
    "        - 返り値: なし\n",
    "\n",
    "**その他**\n",
    "`random`モジュールは以下のように宣言して使いなさい。\n",
    "```python\n",
    "import random as ra\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### class Roomsのデバッグ用プログラム trial()\n",
    "**Q2.** 前問で作ったクラス`Rooms`のデバッグのため，以下をみたす関数`trial()`を定義し，`Rooms`の各インスタンス・メソッドの動作が適切であることを確認しなさい。\n",
    "\n",
    "- 引数\n",
    "    - `a`: デフォルト値は\"right\"\n",
    "    - `Nstate`: 状態数(部屋数)。デフォルト値は5\n",
    "- 処理\n",
    "    - 引数`a=\"right\"`の場合は状態`s=1`から，`a=\"left\"`の場合は状態`s=Nstate`から常に同じ行動`a`を用いて，エピソード終了まで状態遷移を繰り返す。状態の初期設定には，前問の`Rooms.reset()`を用いる。\n",
    "    - 状態遷移には前問で作った`Rooms.step()`を用いる。\n",
    "    - 状態遷移における各ステップの様子は前問で作った`Rooms.render()`を用いて表示する。`Rooms.step()`の返り値である報酬値の値も表示する。\n",
    "    - 関数の終了は，エピソード終了時\n",
    "\n",
    "```python\n",
    "trial()\n",
    "print()\n",
    "trial(\"left\")\n",
    "```\n",
    "上記命令を実行して，以下と**全く同じ結果**が出力されたら合格! **必要に応じて前問の`Rooms`も修正**しなさい。\n",
    "```\n",
    "  | @| 2| 3| 4| 5|  r= -1\n",
    "  | 1| @| 3| 4| 5|  r= -1\n",
    "  | 1| 2| @| 4| 5|  r= -1\n",
    "  | 1| 2| 3| @| 5|  r= -1\n",
    "  | 1| 2| 3| 4| @|  r= -1\n",
    "  | 1| 2| 3| 4| 5|@  r= 10\n",
    "\n",
    "  | 1| 2| 3| 4| @|  r= -1\n",
    "  | 1| 2| 3| @| 5|  r= -1\n",
    "  | 1| 2| @| 4| 5|  r= -1\n",
    "  | 1| @| 3| 4| 5|  r= -1\n",
    "  | @| 2| 3| 4| 5|  r= -1\n",
    " @| 1| 2| 3| 4| 5|  r= -1\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 学習しないエージェント: class Fool\n",
    "**Q3.** 以下のように学習しないエージェントのクラスを作りなさい。\n",
    "\n",
    "**仕様**\n",
    "- クラス名: `Fool`\n",
    "- 初期化メソッド\n",
    "    - 引数とデフォルト値\n",
    "        - `action_list`: とりうる行動の一覧のリスト\n",
    "        - `action=\"random\"` : `Fool`エージェントがとる行動\n",
    "    - 処理: \n",
    "        - 引数`action_list`の値を，インスタンス変数`action_list`に代入\n",
    "        - インスタンス変数`a`の値を以下のように決定する\n",
    "            - 引数`action`の値が引数(リスト)`action_list`の要素内にあるときは，`action`の値\n",
    "            - 上記以外の場合の値は\"random\"\n",
    "- インスタンス・メソッド\n",
    "    - `get_action(state)`\n",
    "        - 引数: `state`\n",
    "        - 返り値: インタンス変数`a`の値によって以下のように決める\n",
    "            - `a=\"random\"`の場合はインスタンス変数`action_list`からランダム選択\n",
    "            - 上記以外の場合は`a`の値\n",
    "        - 注意: 上記のように，返り値の決定に引数`state`は使わないが，今後作るエージェントのクラスとの互換性のために，あえて引数を設けている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Foolの探検: demo_env()\n",
    "\n",
    "**Q4.** 以下は，作成した環境`Rooms`を`Fool`エージェントが探検する関数`demo_env()`である。\n",
    "\n",
    "**引数とデフォルト値**\n",
    "- `env`: 学習する環境\n",
    "- `agent`: 環境を動く行動を決定するエージェント\n",
    "- `max_episode=30`: 繰り返すエピソード数\n",
    "- `max_step=30`: 1エピソードあたりの最大タイムステップ数\n",
    "- `verbose`: 値が`True`のときに限り，以下の`render_step`で指定するエピソード毎に`Rooms.render()`を用いた状態遷移表示をする。(`render_step=10`ならば，第0,10,20,...エピソードの状態遷移を表示する)\n",
    "- `render_step=20`: 状態遷移を表示する頻度設定\n",
    "        \n",
    "**返り値**\n",
    "- `history_steps`: 各エピソードにおける，エピソード終了までのステップ数のリスト\n",
    "- `history_score`: 各エピソードにおいて獲得した総報酬のリスト\n",
    "\n",
    "コメント文を参考にして，プログラムを完成しなさい。\n",
    "\n",
    "```python\n",
    "def demo_env(env, agent, max_episode=30, max_step=30, verbose=False, render_step=10):\n",
    "    # ここに，要素数がmax_episodeであるリストhistory_stepsとhistory_scoreを定義する。いずれも各要素の初期値は0とする\n",
    "\n",
    "    # 各エピソードの総報酬は変数scoreに格納する。そのための命令文は以下のどこかに追加する\n",
    "    for n_episode in range(max_episode):\n",
    "        s=env.reset()\n",
    "        for t in range(max_step):\n",
    "            # ここに，verbose==Trueの場合かつ，render_step回のエピソード実行毎にenv.render()を実行する命令文を書く\n",
    "            action=agent.get_action(s)\n",
    "            s,r,terminal=env.step(action)\n",
    "            if terminal: break # <= if文を1行で書いてみた\n",
    "\n",
    "        if verbose: \n",
    "            # ここに，render_step回のエピソード実行毎にenv.render()を実行する命令文を書く\n",
    "            print(\"Episode {} finished after {} timesteps with {} return\".format(n_episode,t+1,score))#時間tの表示は0からではなく，1からにする\n",
    "\n",
    "        # history_steps の第n_episode要素に，エピソード終了時のt+1を代入する命令文を追加\n",
    "        # history_score の第n_episode要素に，エピソード終了時のscoreを代入する命令文を追加\n",
    "\n",
    "    return(history_steps,history_score)\n",
    "```\n",
    "以上を定義したら，以下を実行して動作確認をすること。\n",
    "```\n",
    "action_list=[\"left\",\"right\"]\n",
    "env=Rooms()\n",
    "right_agent=Fool(action_list,action=\"right\")\n",
    "step,score=demo_env(env,right_agent, max_episode=5, verbose=True, render_step=1)\n",
    "```\n",
    "`demo_env()`の引数も変えてみて，動作に問題がないかよく確認しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4-2**\n",
    "\n",
    "1. 前問の実行結果をよく見て以下を確認しなさい。\n",
    "    1. エージェント位置が部屋の外に出た時点まで表示されていること\n",
    "    2. エピソードごとに表示されるタイムステップ数や総報酬値が適切であること\n",
    "2. 上記のように`right_agent=Fool(\"right\")`と定義した場合，スタート位置が`s=1`となったときの結果は， Q3で`trial(\"right\")`を実行した場合と同じ結果になっていることを確認しなさい。\n",
    "3. `left_agent=Fool(\"left\")`を用いて`demo_env()`を実行しなさい。この場合，スタート位置が`s=5`になったときには，Q3で`trial(\"left\")`を実行した場合と同様の結果になっていることを確認しなさい。\n",
    "4. `fool_agent=Fool(\"random\")`を用いた場合にも適切な行動遷移が得られることを確認しなさい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 学習エージェントクラスQlearnerの構築\n",
    "\n",
    "**Q5.** クラス `Rooms`の環境に対して，報酬を得るための行動学習を行うエージェントのクラス`Qlearner`をつくりなさい。\n",
    "    - 以下の仕様を満たしていれば，メソッドや変数の追加は自由にして良い\n",
    "    - 注意) **各メソッド内のみで使う変数はインスタンス変数にはしないこと!**\n",
    "\n",
    "**仕様**\n",
    "- クラス名: `Qlearner`\n",
    "- 初期化メソッド\n",
    "    - 引数とデフォルト値\n",
    "        - `action_list` : 選択しうる行動のリスト\n",
    "        - `epsilon=0.1` : actionのrandom選択をする確率\n",
    "        - `alpha=0.2`   : learning rate\n",
    "        - `gamma=0.9`: discount rate\n",
    "        - `q0=0`          : Q値の初期値\n",
    "    - インスタンス変数と初期化\n",
    "        - `action_list` : 引数action_listの値で初期化\n",
    "        - `epsilon` : 引数epsilonの値で初期化\n",
    "        - `alpha`   : 引数alphaの値で初期化\n",
    "        - `gamma`: 引数gammaの値で初期化\n",
    "        - `q0`       : 引数q0の値で初期化\n",
    "        - `Q={}`    : 空の辞書。キー`(s,a)`と値(Q値)のペアを格納する\n",
    "- インスタンス・メソッド\n",
    "    - `reset(self)`: 学習結果を初期化する\n",
    "        - 実行内容: 辞書`Q`を空の辞書にする\n",
    "    - `get_q(self, s, a)`\n",
    "        - 引数: \n",
    "            - `s`: 状態\n",
    "            - `a`: 行動\n",
    "        - 辞書Qを参照し，`(s,a)`に対するQ値を返す\n",
    "        - 辞書Qのキーに`(s,a)`がないときにはインスタンス変数`q0`の値を返す\n",
    "    - `get_maxQ(self, s)`\n",
    "        - 引数: \n",
    "            - `s`: 状態\n",
    "        - 返り値: 状態 s に対して，Q値が最大値をとる最適行動を選択した場合の以下の値\n",
    "            - Q値\n",
    "            - 最適行動の個数\n",
    "            - 最適行動のインデックス。インデックスはリスト`action_list`中の順に対応\n",
    "    - `get_action(self, s):`\n",
    "        - 引数: \n",
    "            - `s`: 状態\n",
    "        - 返り値: 状態 s に基づいて以下のように決定した行動\n",
    "            - 確率`epsilon`(インスタンス変数)でランダムな行動選択\n",
    "            - Q値が最大となる行動が一意に決まるときは，その行動\n",
    "            - Q値が最大となる行動が2つあるときは，ランダム選択\n",
    "    - `learning(self, s1, a1, r, s2, terminal)`\n",
    "        - 以下のQ学習則に基づいてQ値(インスタンス変数`Q[(s,a)]`)の更新をする\n",
    "        ```\n",
    "        Q(s,a) <- Q(s,a) + alpha * (r + gamma*max(Q(s')) - Q(s,a))\n",
    "        ```\n",
    "        - 引数:\n",
    "            - `s1`: 学習則のs\n",
    "            - `a1`: 学習則のa\n",
    "            - `r`:  学習則のr\n",
    "            - `s2`: 学習則のs'\n",
    "            - `terminal=False`: エピソード終了状態かどうかを表す引数。今回の処理には使わないが将来のために準備。\n",
    "        - 学習則の計算について\n",
    "            - 学習則の`alpha`, `gamma`はインスタンス変数を用いる\n",
    "            - 学習則右辺の`Q(s,a)`には，インスタンス・メソッド`get_q()`を用いることができる\n",
    "            - 学習則右辺の`max(Q(s'))`には，インスタンス・メソッド`get_maxQ()`の返り値を用いることができる\n",
    "        - 返り値: なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Qlearnerによる学習プログラム: `play_env()`\n",
    "\n",
    "**Q6.**  既に作成した関数`demo_env()`を改造して，環境`Rooms`において，上記で作成したクラス`Qlearner`による行動選択・学習を行う関数`play_env()`を作成し，エピソードとともに学習が進むことを確認しなさい。\n",
    "- **関数名**: `play_env()`\n",
    "- **引数**: `demo_env()`にあった引数の他に，**以下を追加**\n",
    "    - `learning`: \n",
    "        - デフォルト値はTrue\n",
    "        - 学習をするか否かのフラグ\n",
    "\n",
    "- **動作**: \n",
    "    - 引数`learning==False`のときは，`demo_env()`と同じ。\n",
    "    - 引数`learning==True`のときは，`demo_env()`の動作に加え，行動学習も行う\n",
    "    \n",
    "\n",
    "```python\n",
    "def play_env(env, agent, learning=True, max_episode=30, verbose=False, render_step=20):\n",
    "    # ここから下を作る\n",
    "\n",
    "\n",
    "# 以下で動作確認\n",
    "action_list=[\"left\",\"right\"]\n",
    "env=Rooms()\n",
    "q_agent=Qlearner(action_list)\n",
    "play_env(env,q_agent,learning=True,max_episode=30,verbose=True,render_step=10)\n",
    "```\n",
    "その他，引数の値を変えて，動作確認をする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### パフォーマンスのグラフ表示: plot_history()\n",
    "\n",
    "**Q7.** これまでに作成した`demo_env`や`play_env`の返り値である，各エピソードにおける終了までのステップ数と獲得総得点を**グラフ表示**するための命令文および関数`plot_history()`を作成しなさい。\n",
    "\n",
    "- 注意) エピソード終了までのステップ数と獲得総得点の変化は，`subplot`(テキスト参照)等を用いて，それぞれ異なるグフフ上に描画すること\n",
    "- 各軸のタイトルも表示すること\n",
    "- 作成した関数は，`play_env(env,agent)`で実行できることを確認すること。\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(step,score):\n",
    "    # この下に，step,scoreをそれぞれ別のグラフに表示する命令文を追加すること\n",
    "    # 各軸のタイトルも表示すること\n",
    "```\n",
    "作成したら，以下を実行してランダム選択エージェントによるパフォーマンスの推移をグラフ表示できることを確認すること。\n",
    "```\n",
    "action_list=[\"left\",\"right\"]\n",
    "env=Rooms()\n",
    "agent_fool=Fool(action_list)\n",
    "step,score=play_env(env,agent_fool,learning=False) # Foolに学習メソッドの実装はしていないのでlearning=False\n",
    "plot_history(step,score)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7-2.**\n",
    "Q学習エージェントによる学習パフォーマンスの変化も，前問と同様にグラフ表示しなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
